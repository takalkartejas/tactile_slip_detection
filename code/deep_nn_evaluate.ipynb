{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 13:34:41.068936: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-09 13:34:41.888549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-09 13:34:43.456658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:5e:00.0, compute capability: 8.6\n",
      "2024-06-09 13:34:43.457397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10537 MB memory:  -> device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0\n",
      "2024-06-09 13:34:43.457931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 5442 MB memory:  -> device: 2, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:86:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_1 (TimeDi  (None, 8, 64)             15009664  \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 8, 64)             0         \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 1)                 33553     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15043217 (57.39 MB)\n",
      "Trainable params: 328529 (1.25 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 13:34:46.540192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2024-06-09 13:34:46.760909: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-09 13:34:47.021824: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 426.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.021961: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 426.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.022025: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 426.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.022101: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 426.38MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.072958: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 408.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.073000: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2024-06-09 13:34:47.079675: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 408.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.079779: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.084269: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.089458: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-09 13:34:47.089548: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.14MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5/2764 [..............................] - ETA: 1:33 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 13:34:47.574618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2764/2764 [==============================] - 399s 144ms/step\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Conv2D, MaxPooling2D, Flatten, Reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class Manage_data():\n",
    "    def __init__(self):\n",
    "        data_dir='/mnt/data/rag-tt/tactile_images/'\n",
    "        self.data_dir= pathlib.Path(data_dir)\n",
    "        \n",
    "    def find_no_of_images(self, obj_id):\n",
    "        image_dir = os.path.join(self.data_dir, str(obj_id))\n",
    "        image_dir= pathlib.Path(image_dir)\n",
    "        no_of_images= len(list(image_dir.glob('*.jpg')))\n",
    "        return no_of_images\n",
    "    \n",
    "    def balance_data(self, label, image_paths):\n",
    "        # Ensure label and image_paths are numpy arrays\n",
    "        label = np.array(label)\n",
    "        image_paths = np.array(image_paths)\n",
    "        \n",
    "        # Count the total number of zeroes in label\n",
    "        total_zeroes = np.sum(label == 0)\n",
    "        \n",
    "        # Determine the number of zeroes to remove\n",
    "        zeroes_to_remove = max(0, total_zeroes - tune.no_of_nonslip_data)\n",
    "        \n",
    "        # Indices of zero elements\n",
    "        zero_indices = np.where(label == 0)[0]\n",
    "        \n",
    "        # Indices to keep (last self.no_of_nonslip_data zeroes and all ones)\n",
    "        indices_to_keep = np.concatenate((zero_indices[-tune.no_of_nonslip_data:], np.where(label != 0)[0]))\n",
    "        indices_to_keep = np.unique(indices_to_keep)\n",
    "        indices_to_keep = np.sort(indices_to_keep)\n",
    "        \n",
    "        # Create the resulting label array\n",
    "        new_label = label[indices_to_keep]\n",
    "        \n",
    "        # Remove the same number of elements from the start of image_paths\n",
    "        new_image_paths = image_paths[zeroes_to_remove:]\n",
    "        # print('label', label.shape)\n",
    "        # print('image_paths', image_paths.shape)\n",
    "        # print('new_label', new_label.shape)\n",
    "        # print('new_image_paths', new_image_paths.shape)\n",
    "        return new_label, new_image_paths\n",
    "    \n",
    "    def check_pattern(self,label):\n",
    "        # Ensure arr is a numpy array\n",
    "        label = np.array(label)\n",
    "        \n",
    "        # Find the first occurrence of 1\n",
    "        first_one_index = np.argmax(label == 1)\n",
    "        \n",
    "        if np.all(label == 0):  # If there's no 1 in the array, ensure all are 0\n",
    "            return\n",
    "        \n",
    "        # Check if there's no 1 in the array\n",
    "        if np.max(label) == 0:\n",
    "            assert np.all(label == 0), \"Array does not follow the pattern: continuous zeroes followed by continuous ones\"\n",
    "            return\n",
    "        \n",
    "        # Assert all elements before first_one_index are 0\n",
    "        assert np.all(label[:first_one_index] == 0), \"Array does not follow the pattern: continuous zeroes followed by continuous ones\"\n",
    "        \n",
    "        # Assert all elements from first_one_index to the end are 1\n",
    "        assert np.all(label[first_one_index:] == 1), \"Array does not follow the pattern: continuous zeroes followed by continuous ones\"\n",
    "    \n",
    "    def create_slip_instant_labels(self, csv_path):\n",
    "        label = []\n",
    "        slip_values = np.genfromtxt(csv_path, delimiter=',', skip_header=1, usecols=2, dtype=None, encoding=None)\n",
    "        for slip_value in slip_values:\n",
    "            if slip_value < tune.slip_instant_labels:\n",
    "                label.append(0)\n",
    "            else:\n",
    "                label.append(1)\n",
    "        return label\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    def load_data(self, no_of_samples = 600):\n",
    "        file_paths = []\n",
    "        image_paths = []\n",
    "        sequential_image_paths = []\n",
    "        y = []\n",
    "        window_size = tune.sequence_of_images\n",
    "        for obj_id in range(no_of_samples):\n",
    "            no_of_images = self.find_no_of_images(obj_id)\n",
    "            csv_path = os.path.join(self.data_dir, str(obj_id),'slip_log.csv')\n",
    "            if no_of_images < 40 or not os.path.exists(csv_path):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            label2 = self.create_slip_instant_labels(csv_path)\n",
    "            label = np.genfromtxt(csv_path, delimiter=',', skip_header=1, usecols=1, dtype=None, encoding=None)\n",
    "            \n",
    "            for img_id in range(no_of_images):\n",
    "                image_path = os.path.join(self.data_dir, str(obj_id), str(img_id)+ '.jpg')\n",
    "                image_paths.append(image_path)\n",
    "            self.check_pattern(label)\n",
    "            \n",
    "            # label, image_paths = self.balance_data(label,image_paths)    \n",
    "            y.append(label[:-(tune.sequence_of_images-1)])\n",
    "            \n",
    "            for i in range(0, len(image_paths) - (tune.sequence_of_images-1)):  # Ensuring sequences of 5 images\n",
    "                row = image_paths[i:i+tune.sequence_of_images]\n",
    "                sequential_image_paths.append(row)\n",
    "            image_paths = []\n",
    "\n",
    "        y = np.concatenate(y)\n",
    "        self.labels = np.array(y)\n",
    "\n",
    "        self.file_paths = np.array(sequential_image_paths)\n",
    "        \n",
    "    def shuffle_file_paths(self):\n",
    "        # Shuffle the dataset\n",
    "        indices = np.arange(len(self.file_paths))\n",
    "        np.random.shuffle(indices)\n",
    "        self.file_paths = self.file_paths[indices]\n",
    "        self.labels = self.labels[indices]\n",
    "        \n",
    "    def shuffle_train_file_paths(self):\n",
    "        # Shuffle the dataset\n",
    "        indices = np.arange(len(self.train_filepaths))\n",
    "        np.random.shuffle(indices)\n",
    "        self.train_filepaths = self.train_filepaths[indices]\n",
    "        self.train_labels = self.train_labels[indices]\n",
    "        \n",
    "    def create_split_filepaths(self,train=0.7,val=0.2):\n",
    "        dataset_size = len(self.file_paths)\n",
    "        train_size = int(train * dataset_size)\n",
    "\n",
    "        val_size = int(val * dataset_size)\n",
    "        \n",
    "        test_size = dataset_size - train_size - val_size\n",
    "        print('dataset_size=', dataset_size)\n",
    "        print('train size=', train_size)\n",
    "        print('test size=', test_size)\n",
    "        print('val size=', val_size)\n",
    "        self.train_filepaths = self.file_paths[ : train_size]\n",
    "        self.val_filepaths = self.file_paths[train_size : train_size+val_size]\n",
    "        self.test_filepaths = self.file_paths[train_size+val_size : ]\n",
    "        \n",
    "        self.train_labels = self.labels[ : train_size]\n",
    "        self.val_labels = self.labels[train_size : train_size+val_size]\n",
    "        self.test_labels = self.labels[train_size+val_size : ]\n",
    "        \n",
    "        # Check the sizes of the splits\n",
    "        assert len(self.train_filepaths) == train_size, \"Training set size mismatch\"\n",
    "        assert len(self.val_filepaths) == val_size, \"Validation set size mismatch\"\n",
    "        assert len(self.test_filepaths) == test_size, \"Test set size mismatch\"\n",
    "        assert len(self.train_labels) == train_size, \"Training set size mismatch\"\n",
    "        assert len(self.val_labels) == val_size, \"Validation set size mismatch\"\n",
    "        assert len(self.test_labels) == test_size, \"Test set size mismatch\"\n",
    "        \n",
    "    def parse_function_vgg(self, filenames, label):\n",
    "        images = []\n",
    "        for filename in filenames:\n",
    "            image_string = tf.io.read_file(filename)\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "            image_resized = tf.image.resize(image_decoded, [224, 224])  # Adjust size as needed\n",
    "            # Convert image to a float32 tensor and preprocess it for VGG16\n",
    "            image = tf.cast(image_resized, tf.float32)\n",
    "            image = preprocess_input(image)\n",
    "            # Ensure images are float32 and normalized between 0 and 1\n",
    "            images.append(image)\n",
    "        images = tf.stack(images)\n",
    "        return images, label\n",
    "        \n",
    "    def create_dataset(self,file_paths, labels):\n",
    "                # Create a TensorFlow dataset from the file paths and labels\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "        \n",
    "\n",
    "        def wrapped_parse_function(filenames, label):\n",
    "            images, label = tf.py_function(func=self.parse_function_vgg, inp=[filenames, label], Tout=[tf.float32, tf.int64])\n",
    "            images.set_shape((tune.sequence_of_images, 224, 224, 3))  # Explicitly set the shape\n",
    "            label.set_shape([])  # Explicitly set the shape for the label\n",
    "            return images, label\n",
    " \n",
    "        \n",
    "        dataset = dataset.map(wrapped_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        dataset = dataset.batch(tune.batch_size)  # Adjust batch size as needed\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "        \n",
    "    def create_split_datasets(self):\n",
    "        self.train_dataset = self.create_dataset(self.train_filepaths, self.train_labels)\n",
    "        self.val_dataset = self.create_dataset(self.val_filepaths, self.val_labels)\n",
    "        self.test_dataset = self.create_dataset(self.test_filepaths, self.test_labels)\n",
    "    \n",
    "    \n",
    "    def load_evaluation_data(self, no_of_samples=100):\n",
    "        file_paths = []\n",
    "        image_paths = []\n",
    "        sequential_image_paths = []\n",
    "        y = []\n",
    "\n",
    "        for obj_id in range(no_of_samples):\n",
    "            no_of_images = self.find_no_of_images(obj_id)\n",
    "            csv_path = os.path.join(self.data_dir, str(obj_id), 'slip_log.csv')\n",
    "            if no_of_images < 40 or not os.path.exists(csv_path):\n",
    "                continue\n",
    "\n",
    "            label = np.genfromtxt(csv_path, delimiter=',', skip_header=1, usecols=1, dtype=None, encoding=None)\n",
    "\n",
    "            for img_id in range(no_of_images):\n",
    "                image_path = os.path.join(self.data_dir, str(obj_id), str(img_id) + '.jpg')\n",
    "                image_paths.append(image_path)\n",
    "            self.check_pattern(label)\n",
    "\n",
    "            y.append(label[:-(tune.sequence_of_images - 1)])\n",
    "\n",
    "            for i in range(0, len(image_paths) - (tune.sequence_of_images - 1)):  # Ensuring sequences of images\n",
    "                row = image_paths[i:i + tune.sequence_of_images]\n",
    "                sequential_image_paths.append(row)\n",
    "            image_paths = []\n",
    "\n",
    "        y = np.concatenate(y)\n",
    "        eval_labels = np.array(y)\n",
    "        eval_file_paths = np.array(sequential_image_paths)\n",
    "        \n",
    "        return eval_file_paths, eval_labels\n",
    "\n",
    "    def create_evaluation_dataset(self):\n",
    "        eval_file_paths, eval_labels = self.load_evaluation_data()\n",
    "        return self.create_dataset(eval_file_paths, eval_labels)\n",
    "    \n",
    "class create_network():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x =0\n",
    "        \n",
    "    def cnn_lstm1(self):\n",
    "\n",
    "        # Define CNN model\n",
    "        cnn_model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(480, 640, 3),kernel_regularizer=l1(tune.regularizaion_const)),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(32, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(32, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()  # Flatten the spatial dimensions\n",
    "        ])\n",
    "\n",
    "        \n",
    "        # Define LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(64,input_shape=(tune.sequence_of_images, 144768),kernel_regularizer=l1(tune.regularizaion_const) ),\n",
    "            Dense(8, activation='relu', kernel_regularizer=l1(tune.regularizaion_const)),\n",
    "            Dense(1, activation='sigmoid'),\n",
    "        ])\n",
    "\n",
    "        # Combine CNN and LSTM models\n",
    "        self.model = Sequential([\n",
    "            TimeDistributed(cnn_model, input_shape=(tune.sequence_of_images, 480, 640, 3)),  # Apply CNN to each frame in the sequence\n",
    "            (Reshape((tune.sequence_of_images,144768))),\n",
    "            lstm_model,\n",
    "        ])\n",
    "        self.model.summary()\n",
    "\n",
    "    def vgg_lstm(self):\n",
    "        # VGG16 model with pre-trained weights\n",
    "        #include top  false remove the final classification layer\n",
    "        vgg_model = tf.keras.applications.VGG16(weights='imagenet',include_top=False, input_shape=(224, 224, 3))\n",
    "        # Freeze the VGG16 layers if you don't want to train them\n",
    "        \n",
    "        # Retain only the first n layers of the VGG16 model\n",
    "        vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[tune.vgg_layers-1].output)\n",
    "      \n",
    "        for layer in vgg_model.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        additional_conv = Sequential([\n",
    "            vgg_model,\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2))\n",
    "        ])\n",
    "\n",
    "        # Define CNN model\n",
    "        vgg_model_flatten = Sequential([\n",
    "            additional_conv,\n",
    "            # Flatten(),  # Flatten the spatial dimensions\n",
    "            GlobalAveragePooling2D(),  # Use Global Average Pooling instead of Flatten\n",
    "            # Dense(tune.dense_neurons1, activation='relu'),\n",
    "            # Dropout(tune.dropout1)\n",
    "        ])\n",
    "        \n",
    "        vgg_model_flatten.summary()\n",
    "        #25088 is the output of vff_model_flatten\n",
    "        # Define LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(64, input_shape=(tune.sequence_of_images, tune.dense_neurons1)),\n",
    "            Dropout(tune.dropout2),  # Dropout layer to prevent overfitting\n",
    "            Dense(tune.dense_neurons2, activation='relu'),\n",
    "            Dropout(tune.dropout3),\n",
    "            Dense(1, activation='sigmoid'),\n",
    "                ])\n",
    "\n",
    "        # Combine CNN and LSTM models\n",
    "        self.model = Sequential([\n",
    "            TimeDistributed(vgg_model_flatten, input_shape=(tune.sequence_of_images, 224, 224, 3)),  # Apply CNN to each frame in the sequence\n",
    "            (Reshape((tune.sequence_of_images,tune.dense_neurons1))),\n",
    "            lstm_model,\n",
    "        ])\n",
    "        vgg_model.summary()\n",
    "        \n",
    "        self.model.summary()\n",
    "        \n",
    "    def train(self, train_dataset, val_dataset):\n",
    "        cp = ModelCheckpoint('model_vgg_test/',monitor='val_accuracy',save_best_only=True)\n",
    "            # EarlyStopping callback to stop training when validation accuracy stops improving\n",
    "        es = EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        #tensor board\n",
    "        tb= tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                # Shuffle training dataset before each epoch\n",
    "        # train_dataset_shuffled = train_dataset.shuffle(buffer_size=train_dataset.cardinality(), reshuffle_each_iteration=tune.reshuffle)\n",
    "        self.model.compile(loss=BinaryCrossentropy(), optimizer=Adam(learning_rate=tune.learning_rate),metrics=['accuracy'])\n",
    "        self.model.fit(train_dataset,validation_data=val_dataset, epochs=tune.epochs, callbacks=[cp,es,accuracy_history])\n",
    "        \n",
    "class AccuracyHistory(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch_count = []\n",
    "        self.train_accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        self.sequence_of_image = []\n",
    "        self.learning_rate = []\n",
    "        self.reshuffle =  []\n",
    "        self.dropout1 = []\n",
    "        self.dropout2 = []\n",
    "        self.dropout3 = []\n",
    "        self.dropout4 = []\n",
    "        self.regularization_constant = []\n",
    "        self.batch_size = []\n",
    "        self.dense_neurons1 =[]\n",
    "        self.dense_neurons2 =[]\n",
    "        self.no_of_samples = []\n",
    "        self.epochs  = []\n",
    "        self.vgg_layers = []\n",
    "        self.other_param = []\n",
    "        self.no_of_nonslip_data = []   \n",
    "        self.slip_instant_labels = []\n",
    "             \n",
    "    def reset_dict(self):\n",
    "        self.epoch_count = []\n",
    "        self.train_accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        self.sequence_of_image = []\n",
    "        self.learning_rate = []\n",
    "        self.reshuffle =  []\n",
    "        self.dropout1 = []\n",
    "        self.dropout2 = []\n",
    "        self.dropout3 = []\n",
    "        self.dropout4 = []\n",
    "        self.regularization_constant = []\n",
    "        self.batch_size = []\n",
    "        self.dense_neurons1 =[]\n",
    "        self.dense_neurons2 =[]\n",
    "        self.no_of_samples = []\n",
    "        self.epochs  = []\n",
    "        self.vgg_layers = []\n",
    "        self.other_param = []\n",
    "        self.no_of_nonslip_data = []\n",
    "        self.slip_instant_labels = [] \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={'accuracy':0,'val_accuracy':0}):\n",
    "        self.epoch_count.append(epoch + 1)\n",
    "        self.train_accuracy.append(logs.get('accuracy'))\n",
    "        self.val_accuracy.append(logs.get('val_accuracy'))\n",
    "        self.sequence_of_image.append(tune.sequence_of_images)\n",
    "        self.learning_rate.append(tune.learning_rate)\n",
    "        self.reshuffle.append(tune.reshuffle)\n",
    "        self.dropout1.append(tune.dropout1)\n",
    "        self.dropout2.append(tune.dropout2)\n",
    "        self.dropout3.append(tune.dropout3)\n",
    "        self.dropout4.append(tune.dropout4)\n",
    "        self.regularization_constant.append(tune.regularization_constant)\n",
    "        self.batch_size.append(tune.batch_size)\n",
    "        self.dense_neurons1.append(tune.dense_neurons1)\n",
    "        self.dense_neurons2.append(tune.dense_neurons2)\n",
    "        self.no_of_samples.append(tune.no_of_samples)\n",
    "        self.epochs.append(tune.epochs )\n",
    "        self.vgg_layers.append(tune.vgg_layers)\n",
    "        self.other_param.append(tune.other_param)\n",
    "        self.no_of_nonslip_data.append(tune.no_of_nonslip_data)\n",
    "        self.slip_instant_labels.append(tune.slip_instant_labels)\n",
    "        \n",
    "    def create_accuracy_dataframe(self):\n",
    "        accuracy_df = pd.DataFrame({\n",
    "            'Epoch': self.epoch_count,\n",
    "            'Train_Accuracy': self.train_accuracy,\n",
    "            'Val_Accuracy': self.val_accuracy,\n",
    "            'Sequence_of_Image': self.sequence_of_image,\n",
    "            'Learning_Rate': self.learning_rate,\n",
    "            'Reshuffle': self.reshuffle,\n",
    "            'Dropout1': self.dropout1,\n",
    "            'Dropout2': self.dropout2,\n",
    "            'Dropout3': self.dropout3,\n",
    "            'Dropout4': self.dropout4,\n",
    "            'Regularization_Constant': self.regularization_constant,\n",
    "            'Batch_Size': self.batch_size,\n",
    "            'dense_neurons1': self.dense_neurons1,\n",
    "            'dense_neurons2': self.dense_neurons2,\n",
    "            'no_of_samples':self.no_of_samples,\n",
    "            'epochs':self.epochs, \n",
    "            'vgg_layers':self.vgg_layers,\n",
    "            'other_param':self.other_param,\n",
    "            'no_of_nonslip_data':self.no_of_nonslip_data,\n",
    "            'slip_instant_labels':self.slip_instant_labels\n",
    "        })\n",
    "        return accuracy_df    \n",
    "    def save_to_csv(self, accuracy_df):\n",
    "            # Start with summary1.csv\n",
    "            file_number = 0\n",
    "            while True:\n",
    "                filename = 'tune_log/'+'summary' + str(file_number) + '.csv'\n",
    "                # Check if the file already exists\n",
    "                if not os.path.isfile(filename):\n",
    "                    break\n",
    "                file_number += 1\n",
    "            filename_model ='tune_log/'+ 'model' + str(file_number) + '.h5'\n",
    "            network.model.save(filename_model)\n",
    "            accuracy_df.to_csv(filename, index=False)    \n",
    "        \n",
    "class tuning():\n",
    "    def __init__(self):\n",
    "        self.sequence_of_image_array = [6,8,9,10]\n",
    "        self.learning_rate_array = [0.00005,0.00003, 0.00004, 0.00001,0.0000008, 0.000006 ]\n",
    "        self.reshuffle_array=[False, True]\n",
    "        self.regularization_constant_array = [0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "        self.dense_neurons2_array = [8, 16, 32]\n",
    "        self.vgg_layers_array= [7,11,15,19]\n",
    "        self.sequence_of_images =  self.sequence_of_image_array[1]\n",
    "        self.learning_rate = self.learning_rate_array[1]\n",
    "        self.reshuffle =  self.reshuffle_array[0]\n",
    "        self.dropout1 = 0.5\n",
    "        self.dropout2 = 0.5\n",
    "        self.dropout3 = 0.5\n",
    "        self.dropout4 = 0.5\n",
    "        self.regularization_constant = 0.001\n",
    "        self.batch_size = 4\n",
    "        self.dense_neurons1 = 64\n",
    "        self.dense_neurons2 = 8\n",
    "        self.csv_id = 0\n",
    "        self.no_of_samples = 100\n",
    "        self.epochs = 50\n",
    "        self.vgg_layers = 19\n",
    "        self.other_param='additional cnn + global average'\n",
    "        self.no_of_nonslip_data = 8\n",
    "        self.slip_instant_labels = 0.001\n",
    "        \n",
    "    def start_training(self):\n",
    "        try:\n",
    "            manage_data.load_data(no_of_samples=self.no_of_samples)\n",
    "            # manage_data.shuffle_file_paths()\n",
    "            manage_data.create_split_filepaths()\n",
    "            manage_data.shuffle_train_file_paths()\n",
    "            manage_data.create_split_datasets()\n",
    "            network.vgg_lstm()\n",
    "            \n",
    "            #print the tuning parametrs before training\n",
    "            accuracy_history.on_epoch_end(0)\n",
    "            df = accuracy_history.create_accuracy_dataframe()\n",
    "            # Transpose the DataFrame\n",
    "            df_transposed = df.transpose()\n",
    "            print(df_transposed)\n",
    "            network.train(manage_data.train_dataset, manage_data.val_dataset)\n",
    "        \n",
    "        # Ensure accuracy data is saved even if training is interrupted \n",
    "        finally:        \n",
    "            # Create a DataFrame from the accuracy history lists\n",
    "            accuracy_df = accuracy_history.create_accuracy_dataframe()\n",
    "\n",
    "            # Save the DataFrame to a CSV file\n",
    "            accuracy_history.save_to_csv(accuracy_df)\n",
    "            accuracy_history.reset_dict()                    \n",
    "    def Tune(self):\n",
    "   \n",
    "        for value in self.sequence_of_image_array:\n",
    "            self.sequence_of_images = value           \n",
    "            self.start_training()\n",
    "        self.sequence_of_images = 5\n",
    "        \n",
    "\n",
    "def list_subdirectories(directory):\n",
    "    try:\n",
    "        # Get the list of all entries in the directory\n",
    "        entries = os.listdir(directory)\n",
    "        \n",
    "        # Filter out and list only the directories\n",
    "        subdirs = [entry for entry in entries if os.path.isdir(os.path.join(directory, entry))]\n",
    "        \n",
    "        return subdirs\n",
    "    except FileNotFoundError:\n",
    "        return f\"The directory '{directory}' does not exist.\"\n",
    "    except PermissionError:\n",
    "        return f\"Permission denied to access '{directory}'.\"\n",
    "    \n",
    "\n",
    "manage_data = Manage_data()\n",
    "network = create_network()\n",
    "manage_data= Manage_data()\n",
    "tune = tuning()\n",
    "accuracy_history = AccuracyHistory()\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the .h5 file\n",
    "model = load_model('./tune_log/model13.h5')\n",
    "# Print the model summary to confirm it was loaded correctly\n",
    "model.summary()\n",
    "\n",
    "# Create evaluation dataset\n",
    "evaluation_dataset = manage_data.create_evaluation_dataset()\n",
    "\n",
    "# Predict labels for the evaluation dataset\n",
    "y_predicted = model.predict(evaluation_dataset)\n",
    "\n",
    "\n",
    "\n",
    "# manage_data.load_data(no_of_samples=500)\n",
    "# # manage_data.shuffle_file_paths()\n",
    "# manage_data.create_split_filepaths()\n",
    "# manage_data.shuffle_train_file_paths()\n",
    "# manage_data.create_split_datasets()\n",
    "# for X in manage_data.train_dataset:\n",
    "    \n",
    "#     for X1 in X:\n",
    "#         print('X= ',X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11053, 1)\n"
     ]
    }
   ],
   "source": [
    "y_predicted = np.array(y_predicted)\n",
    "# Print without truncation\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(y_predicted.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =[]\n",
    "for element in y_predicted:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels from the evaluation dataset\n",
    "def extract_labels_from_dataset(dataset):\n",
    "    labels = []\n",
    "    for _, label_batch in dataset:\n",
    "        labels.extend(label_batch.numpy())\n",
    "    return np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels\n",
    "evaluation_labels = extract_labels_from_dataset(evaluation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11053,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
